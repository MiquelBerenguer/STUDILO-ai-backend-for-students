#!/usr/bin/env python3
import asyncio
import json
import logging
import os
import io
import aio_pika 
import google.generativeai as genai
from minio import Minio
from pdf2image import convert_from_bytes
from tenacity import retry, stop_after_attempt, wait_exponential

# --- CORRECCIÃ“N DE IMPORTS ---
# Dockerfile mapea src/shared -> /app/shared
# PYTHONPATH=/app permite importar 'shared' directamente
from shared.vectordb.chunker import EngineeringChunker 
from shared.vectordb.qdrant import QdrantService
from shared.vectordb.client import VectorChunk

# --- CONFIGURACIÃ“N ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
logger = logging.getLogger("EngineeringWorkerAsync")

GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
if GOOGLE_API_KEY:
    genai.configure(api_key=GOOGLE_API_KEY)

class EngineeringWorkerAsync:
    def __init__(self):
        self.rabbitmq_url = os.getenv('RABBITMQ_URL', 'amqp://guest:guest@rabbitmq:5672/')
        
        # Ajuste para usar las variables de entorno correctas de tu docker-compose
        self.minio = Minio(
            os.getenv('MINIO_ENDPOINT', 'minio:9000'),
            access_key=os.getenv('MINIO_USER', 'tutoria_admin'), # <--- Coincide con docker-compose
            secret_key=os.getenv('MINIO_PASSWORD', 'TutorIA_Secure_Pass_2024!'), # <--- Coincide con docker-compose
            secure=False
        )
        
        self.model = genai.GenerativeModel('gemini-1.5-flash')
        self.chunker = EngineeringChunker(chunk_size=1000, chunk_overlap=200)
        
        # Nuestro servicio Qdrant ya es nativo async
        self.qdrant = QdrantService()

    # --- WRAPPERS PARA NO BLOQUEAR EL EVENT LOOP ---

    async def _download_pdf_async(self, bucket, key):
        """Descarga de MinIO en un hilo separado"""
        loop = asyncio.get_running_loop()
        return await loop.run_in_executor(None, lambda: self.minio.get_object(bucket, key).read())

    async def _render_images_async(self, pdf_bytes):
        """Renderizado de PDF (CPU intensivo) en hilo separado"""
        loop = asyncio.get_running_loop()
        return await loop.run_in_executor(None, lambda: convert_from_bytes(pdf_bytes, dpi=150, fmt='jpeg'))

    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
    async def _call_gemini_async(self, pil_image):
        """Llamada a Gemini con reintentos automÃ¡ticos"""
        prompt = """
        ActÃºa como experto en transcripciÃ³n LaTeX de IngenierÃ­a. 
        Tu tarea: Transcribe TODO el contenido de esta imagen a formato Markdown.

        Reglas CRÃTICAS:
        1. Ecuaciones en lÃ­nea usa un solo signo dÃ³lar: $ E = mc^2 $
        2. Ecuaciones en bloque usa doble signo dÃ³lar: $$ \sum_{i=0}^n x_i $$
        3. Matrices: \\begin{bmatrix}...\\end{bmatrix}
        4. SOLO devuelve el contenido Markdown, sin introducciones.
        """
        loop = asyncio.get_running_loop()
        # Gemini SDK es sÃ­ncrono, lo envolvemos
        response = await loop.run_in_executor(None, lambda: self.model.generate_content([prompt, pil_image]))
        return response.text

    # --- LÃ“GICA PRINCIPAL ---

    async def process_message(self, message: aio_pika.IncomingMessage):
        async with message.process():
            data = json.loads(message.body)
            job_id = data.get('job_id')
            logger.info(f"âš¡ [Job {job_id}] Iniciando Pipeline AsÃ­ncrono...")

            try:
                # 1. Descargar PDF
                bucket = data.get('minio_bucket', 'uploads')
                key = data.get('minio_object_key')
                pdf_data = await self._download_pdf_async(bucket, key)

                # 2. Renderizar PDF a ImÃ¡genes
                images = await self._render_images_async(pdf_data)
                
                full_markdown = ""

                # 3. Procesar con Gemini (Async Loop)
                for i, img in enumerate(images):
                    logger.info(f"   [Job {job_id}] Vision Pag {i+1}/{len(images)}...")
                    page_md = await self._call_gemini_async(img)
                    full_markdown += f"\n\n\n{page_md}"

                # 4. Guardar Backup MD en MinIO
                md_bytes = full_markdown.encode('utf-8')
                loop = asyncio.get_running_loop()
                md_key = f"{job_id}/processed.md"
                await loop.run_in_executor(None, lambda: self.minio.put_object(
                    'processed', md_key, io.BytesIO(md_bytes), len(md_bytes)
                ))
                logger.info(f"ðŸ’¾ Backup guardado en MinIO: {md_key}")

                # 5. Chunking (CPU Bound)
                text_chunks = await loop.run_in_executor(None, lambda: self.chunker.split_text(full_markdown))
                
                vector_chunks = []
                for idx, text in enumerate(text_chunks):
                    vector_chunks.append(VectorChunk(
                        id=f"{job_id}_{idx}", # ID Ãºnico simple
                        text=text,
                        metadata={
                            "source": key, 
                            "job_id": job_id,
                            "filename": data.get("filename", "unknown")
                        }
                    ))

                # 6. Indexar en Qdrant (NATIVO ASYNC)
                if vector_chunks:
                    logger.info(f"ðŸ§  Insertando {len(vector_chunks)} vectores en Qdrant...")
                    await self.qdrant.upsert_chunks(vector_chunks)

                logger.info(f"âœ… [Job {job_id}] FINALIZADO EXITOSAMENTE")

            except Exception as e:
                logger.error(f"ðŸ”¥ Error fatal procesando Job {job_id}: {e}")
                # Al salir con excepciÃ³n, aio_pika harÃ¡ NACK/Reject automÃ¡ticamente
                raise e

    async def run(self):
        """Loop principal del Worker"""
        
        # 1. Asegurar colecciÃ³n Qdrant
        await self.qdrant.ensure_collection()
        
        # 2. Conectar a RabbitMQ
        connection = await aio_pika.connect_robust(self.rabbitmq_url)
        
        async with connection:
            channel = await connection.channel()
            
            # Prefetch count 1 para control de RAM
            await channel.set_qos(prefetch_count=1)
            
            # Declarar cola
            queue = await channel.declare_queue("pdf.process.engineering", durable=True)
            
            logger.info("ðŸš€ Worker AsÃ­ncrono ESCUCHANDO mensajes...")
            
            # Empezar a consumir
            await queue.consume(self.process_message)
            
            # Mantener vivo
            await asyncio.Future()

if __name__ == "__main__":
    try:
        asyncio.run(EngineeringWorkerAsync().run())
    except KeyboardInterrupt:
        logger.info("ðŸ›‘ Worker detenido manualmente")