# Configuración del servidor
PORT=3003
NODE_ENV=development

# API Keys para embeddings
OPENAI_API_KEY=tu_clave_openai_aqui
COHERE_API_KEY=tu_clave_cohere_aqui

# Configuración de base de datos vectorial
VECTOR_DB_TYPE=local
# Opciones: local, pinecone, chroma, hnswlib

# Pinecone (para producción)
PINECONE_API_KEY=tu_clave_pinecone_aqui
PINECONE_ENVIRONMENT=us-west1-gcp-free
PINECONE_INDEX_NAME=tutor-ia-embeddings

# ChromaDB (alternativa local)
CHROMA_HOST=localhost
CHROMA_PORT=8000
CHROMA_COLLECTION_NAME=educational_documents

# Configuración de embeddings
EMBEDDING_MODEL=text-embedding-ada-002
EMBEDDING_DIMENSIONS=1536
MAX_CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# Configuración de búsqueda
SIMILARITY_THRESHOLD=0.75
MAX_SEARCH_RESULTS=10
ENABLE_SEMANTIC_CACHE=true

# Configuración de procesamiento de texto
TEXT_PREPROCESSING=true
REMOVE_STOPWORDS=true
LANGUAGE=es
MIN_TEXT_LENGTH=50
MAX_TEXT_LENGTH=5000

# Configuración de rate limiting
MAX_REQUESTS_PER_MINUTE=100
MAX_EMBEDDINGS_PER_REQUEST=50

# Configuración de archivos
UPLOAD_PATH=./uploads
MAX_FILE_SIZE=10MB
ALLOWED_EXTENSIONS=pdf,txt,docx,md

# Base de datos local para metadatos
DATABASE_PATH=./data/vectordb.sqlite
ENABLE_BACKUP=true
BACKUP_INTERVAL=24h

# Configuración de logs
LOG_LEVEL=info
LOG_FILE=logs/vectordb-service.log
LOG_EMBEDDINGS=false
LOG_SEARCH_QUERIES=true

# URLs de otros servicios
AI_SERVICE_URL=http://localhost:3002
AUTH_SERVICE_URL=http://localhost:3001
API_GATEWAY_URL=http://localhost:3000

# Configuración de rendimiento
BATCH_SIZE=100
PARALLEL_PROCESSING=true
MAX_CONCURRENT_REQUESTS=10

# Configuración de cache
CACHE_EMBEDDINGS=true
CACHE_TTL=3600
CACHE_MAX_SIZE=1000